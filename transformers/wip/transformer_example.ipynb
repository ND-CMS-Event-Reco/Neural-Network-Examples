{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c9d73bb-e8d5-4aeb-a928-93db9ac6241c",
   "metadata": {
    "id": "2c9d73bb-e8d5-4aeb-a928-93db9ac6241c"
   },
   "source": [
    "# Transformer boilerplate code + how to use it\n",
    "##### by Daniel Melchor (dmh672@gmail.com)\n",
    "\n",
    "# https://towardsdatascience.com/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31985af0-d58e-4d01-8432-065537022502",
   "metadata": {
    "id": "31985af0-d58e-4d01-8432-065537022502"
   },
   "source": [
    "---\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "446258e5-7cf2-4a73-8dd7-7b7a43fdd98e",
   "metadata": {
    "id": "446258e5-7cf2-4a73-8dd7-7b7a43fdd98e",
    "outputId": "47b53fa2-a24f-4b6a-baca-90d30bdb34a9"
   },
   "outputs": [],
   "source": [
    "!pip install torch numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3539f61f-fe7d-4428-b074-327a883f7f6e",
   "metadata": {
    "id": "3539f61f-fe7d-4428-b074-327a883f7f6e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c72c2ada-2106-4505-82f5-086e518080a5",
   "metadata": {
    "id": "c72c2ada-2106-4505-82f5-086e518080a5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim_model, dropout_p, max_len):\n",
    "        super().__init__()\n",
    "        # Modified version from: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "        # max_len determines how far the position can have an effect on a token (window)\n",
    "        \n",
    "        # Info\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        # Encoding - From formula\n",
    "        pos_encoding = torch.zeros(max_len, dim_model)\n",
    "        positions_list = torch.arange(0, max_len, dtype=torch.long).view(-1, 1) # 0, 1, 2, 3, 4, 5\n",
    "        division_term = torch.exp(torch.arange(0, dim_model, 2).long() * (-math.log(10000.0)) / dim_model) # 1000^(2i/dim_model)\n",
    "        \n",
    "        # PE(pos, 2i) = sin(pos/1000^(2i/dim_model))\n",
    "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
    "        \n",
    "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
    "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
    "        \n",
    "        # Saving buffer (same as parameter without gradients needed)\n",
    "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
    "        \n",
    "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
    "        # Residual connection + pos encoding\n",
    "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "588b2729-866c-470a-aca7-6a3c5ea0b192",
   "metadata": {
    "id": "588b2729-866c-470a-aca7-6a3c5ea0b192",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Model from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/p/c80afbc9ffb1/\n",
    "    \"\"\"\n",
    "    # Constructor\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_tokens,\n",
    "        dim_model,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        dropout_p,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # INFO\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.dim_model = dim_model\n",
    "\n",
    "        # LAYERS\n",
    "        self.positional_encoder = PositionalEncoding(\n",
    "            dim_model=dim_model, dropout_p=dropout_p, max_len=5000\n",
    "        )\n",
    "        self.embedding = nn.Embedding(num_tokens, dim_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=dim_model,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dropout=dropout_p,\n",
    "        )\n",
    "        self.out = nn.Linear(dim_model, num_tokens)\n",
    "        \n",
    "    def forward(self, src, tgt, tgt_mask=None, src_pad_mask=None, tgt_pad_mask=None):\n",
    "        # Src size must be (batch_size, src sequence length)\n",
    "        # Tgt size must be (batch_size, tgt sequence length)\n",
    "\n",
    "        # Embedding + positional encoding - Out size = (batch_size, sequence length, dim_model)\n",
    "        src = self.embedding(src) * math.sqrt(self.dim_model)\n",
    "        tgt = self.embedding(tgt) * math.sqrt(self.dim_model)\n",
    "        src = self.positional_encoder(src)\n",
    "        tgt = self.positional_encoder(tgt)\n",
    "        \n",
    "        # We could use the parameter batch_first=True, but our KDL version doesn't support it yet, so we permute\n",
    "        # to obtain size (sequence length, batch_size, dim_model),\n",
    "        src = src.permute(1,0,2)\n",
    "        tgt = tgt.permute(1,0,2)\n",
    "\n",
    "        # Transformer blocks - Out size = (sequence length, batch_size, num_tokens)\n",
    "        transformer_out = self.transformer(src, tgt, tgt_mask=tgt_mask, src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask)\n",
    "        out = self.out(transformer_out)\n",
    "        \n",
    "        return out\n",
    "      \n",
    "    def get_tgt_mask(self, size) -> torch.tensor:\n",
    "        # Generates a squeare matrix where the each row allows one word more to be seen\n",
    "        mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
    "        mask = mask.float()\n",
    "        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
    "        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
    "        \n",
    "        # EX for size=5:\n",
    "        # [[0., -inf, -inf, -inf, -inf],\n",
    "        #  [0.,   0., -inf, -inf, -inf],\n",
    "        #  [0.,   0.,   0., -inf, -inf],\n",
    "        #  [0.,   0.,   0.,   0., -inf],\n",
    "        #  [0.,   0.,   0.,   0.,   0.]]\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def create_pad_mask(self, matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
    "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
    "        # [False, False, False, True, True, True]\n",
    "        return (matrix == pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8ac39c4a-ab17-4487-a1ab-2b107e880574",
   "metadata": {
    "id": "8ac39c4a-ab17-4487-a1ab-2b107e880574",
    "outputId": "3ef96b46-f053-4d42-d2d2-c027c245f1d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562 batches of size 16\n",
      "187 batches of size 16\n"
     ]
    }
   ],
   "source": [
    "# If going from length 8 -> length 4, do SOS at [4] at put zeros for \n",
    "# the rest to keep length constant \n",
    "\n",
    "def generate_random_data(n):\n",
    "    SOS_token = np.array([8]) # For old, np.array([2])\n",
    "    EOS_token = np.array([9]) # For old, np.array([3])\n",
    "    length = 8 \n",
    "\n",
    "    data = []\n",
    "\n",
    "    for i in range(n):\n",
    "        X = np.random.randint(0, 3, length)\n",
    "        y = np.zeros(length)\n",
    "        for i in range(int(8/2)):\n",
    "            y[i] = X[2*i] + X[2*i+1]\n",
    "        X = np.concatenate((SOS_token, X, EOS_token))\n",
    "        y = np.concatenate((SOS_token, y, EOS_token))\n",
    "        data.append([X, y])\n",
    "        \n",
    "    return data\n",
    "\n",
    "def batchify_data(data, batch_size=16, padding=False, padding_token=-1):\n",
    "    batches = []\n",
    "    for idx in range(0, len(data), batch_size):\n",
    "        # We make sure we dont get the last bit if its not batch_size size\n",
    "        if idx + batch_size < len(data):\n",
    "            # Here you would need to get the max length of the batch,\n",
    "            # and normalize the length with the PAD token.\n",
    "            if padding:\n",
    "                max_batch_length = 0\n",
    "\n",
    "                # Get longest sentence in batch\n",
    "                for seq in data[idx : idx + batch_size]:\n",
    "                    if len(seq) > max_batch_length:\n",
    "                        max_batch_length = len(seq)\n",
    "\n",
    "                # Append X padding tokens until it reaches the max length\n",
    "                for seq_idx in range(batch_size):\n",
    "                    remaining_length = max_bath_length - len(data[idx + seq_idx])\n",
    "                    data[idx + seq_idx] += [padding_token] * remaining_length\n",
    "                    \n",
    "            batches.append(np.array(data[idx : idx + batch_size]).astype(np.int64))\n",
    "\n",
    "    print(f\"{len(batches)} batches of size {batch_size}\")\n",
    "\n",
    "    return batches\n",
    "\n",
    "\n",
    "train_data = generate_random_data(9000)\n",
    "val_data = generate_random_data(3000)\n",
    "train_dataloader = batchify_data(train_data)\n",
    "val_dataloader = batchify_data(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6043e5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([8, 0, 2, 1, 2, 2, 1, 0, 1, 9]), array([8., 2., 3., 3., 1., 0., 0., 0., 0., 9.])]\n"
     ]
    }
   ],
   "source": [
    "n = 20\n",
    "data = generate_random_data(n)\n",
    "print(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4d04a60a-f013-4eda-b056-fc9bb1b1ea79",
   "metadata": {
    "id": "4d04a60a-f013-4eda-b056-fc9bb1b1ea79"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Transformer(\n",
    "    num_tokens=16, dim_model=8, num_heads=2, num_encoder_layers=3, num_decoder_layers=3, dropout_p=0.1\n",
    ").to(device)\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# CrossEntropyLoss -> may be typically used for categorization problems\n",
    "# Check more on that\n",
    "# Try MSE Loss next time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7bc6949f-2d59-44c3-8198-037e115106aa",
   "metadata": {
    "id": "7bc6949f-2d59-44c3-8198-037e115106aa"
   },
   "outputs": [],
   "source": [
    "# Remember to dig into pred, y_input, and y_expected within training\n",
    "# and validation\n",
    "\n",
    "def train_loop(model, opt, loss_fn, dataloader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        X, y = batch[:, 0], batch[:, 1]\n",
    "        X, y = torch.tensor(X).to(device), torch.tensor(y).to(device)\n",
    "\n",
    "        # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
    "        y_input = y[:,:-1]\n",
    "        y_expected = y[:,1:]\n",
    "        \n",
    "        # Get mask to mask out the next words\n",
    "        sequence_length = y_input.size(1)\n",
    "        tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
    "\n",
    "        # Standard training except we pass in y_input and tgt_mask\n",
    "        pred = model(X, y_input, tgt_mask)\n",
    "\n",
    "        # print(pred.size())\n",
    "        # print(y_expected.size())\n",
    "        \n",
    "        # Permute pred to have batch size first again\n",
    "        pred = pred.permute(1, 2, 0)      \n",
    "        loss = (loss_fn(pred, y_expected)).type(torch.float)\n",
    "        print(loss)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "        total_loss += loss.detach().item()\n",
    "        \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c23630c9-ce84-4996-8d8c-ff7919303331",
   "metadata": {
    "id": "c23630c9-ce84-4996-8d8c-ff7919303331"
   },
   "outputs": [],
   "source": [
    "def validation_loop(model, loss_fn, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X, y = batch[:, 0], batch[:, 1]\n",
    "            X, y = torch.tensor(X, dtype=torch.float, device=device), torch.tensor(y, dtype=torch.float, device=device)\n",
    "\n",
    "            # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
    "            y_input = y[:,:-1]\n",
    "            y_expected = y[:,1:]\n",
    "            \n",
    "            # Get mask to mask out the next words\n",
    "            sequence_length = y_input.size(1)\n",
    "            tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
    "\n",
    "            # Standard training except we pass in y_input and src_mask\n",
    "            pred = model(X, y_input, tgt_mask)\n",
    "\n",
    "            # Permute pred to have batch size first again\n",
    "            pred = pred.permute(1, 2, 0)      \n",
    "            loss = loss_fn(pred, y_expected)\n",
    "            total_loss += loss.detach().item()\n",
    "        \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5e57ba93-cc8f-4b12-870f-6aed4dce94ab",
   "metadata": {
    "id": "5e57ba93-cc8f-4b12-870f-6aed4dce94ab",
    "outputId": "da2b56bb-f094-45fe-efe3-76666acb68f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validating model\n",
      "------------------------- Epoch 1 -------------------------\n",
      "tensor(11.7370, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found dtype Long but expected Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_31104/2391614102.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrain_loss_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_loss_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mtrain_loss_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_loss_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_31104/2391614102.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(model, opt, loss_fn, train_dataloader, val_dataloader, epochs)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"Epoch {epoch + 1}\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mtrain_loss_list\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_31104/3993746742.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(model, opt, loss_fn, dataloader)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Found dtype Long but expected Float"
     ]
    }
   ],
   "source": [
    "def fit(model, opt, loss_fn, train_dataloader, val_dataloader, epochs):\n",
    "    # Used for plotting later on\n",
    "    train_loss_list, validation_loss_list = [], []\n",
    "    \n",
    "    print(\"Training and validating model\")\n",
    "    for epoch in range(epochs):\n",
    "        print(\"-\"*25, f\"Epoch {epoch + 1}\",\"-\"*25)\n",
    "        \n",
    "        train_loss = train_loop(model, opt, loss_fn, train_dataloader)\n",
    "        train_loss_list += [train_loss]\n",
    "        \n",
    "        validation_loss = validation_loop(model, loss_fn, val_dataloader)\n",
    "        validation_loss_list += [validation_loss]\n",
    "        \n",
    "        print(f\"Training loss: {train_loss:.4f}\")\n",
    "        print(f\"Validation loss: {validation_loss:.4f}\")\n",
    "        print()\n",
    "        \n",
    "    return train_loss_list, validation_loss_list\n",
    "    \n",
    "train_loss_list, validation_loss_list = fit(model, opt, loss_fn, train_dataloader, val_dataloader, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40f805ad-7748-4785-9066-c5500287a4af",
   "metadata": {
    "id": "40f805ad-7748-4785-9066-c5500287a4af",
    "outputId": "7d3e38be-0382-4311-9beb-15c60b3177d5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_list, label = \"Train loss\")\n",
    "plt.plot(validation_loss_list, label = \"Validation loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5df24c30-15b0-471a-ac4d-a0975fbc6a7d",
   "metadata": {
    "id": "5df24c30-15b0-471a-ac4d-a0975fbc6a7d",
    "outputId": "7a7d4a5b-4f10-4cf4-cbe2-f204097bbf19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1\n",
      "Input: [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Continuation: [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Example 2\n",
      "Input: [1, 2, 1, 1, 1, 1, 2, 1]\n",
      "Continuation: [3, 3, 3, 3, 3, 3, 3, 3]\n",
      "\n",
      "Example 3\n",
      "Input: [1, 0, 1, 0, 1, 0, 1, 0]\n",
      "Continuation: [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "Example 4\n",
      "Input: [0, 1, 0, 1, 0, 1, 3, 1]\n",
      "Continuation: [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "Example 5\n",
      "Input: [0, 1, 2, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "Continuation: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "Example 6\n",
      "Input: [0, 0, 0, 1, 0, 0, 0, 1]\n",
      "Continuation: [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict(model, input_sequence, max_length=15, SOS_token=8, EOS_token=9):\n",
    "    model.eval()\n",
    "    \n",
    "    y_input = torch.tensor([[SOS_token]], dtype=torch.float, device=device)\n",
    "    num_tokens = len(input_sequence[0])\n",
    "    \n",
    "    # Asks model to give only one item, the next thing it thinks is most probable \n",
    "    # to continue the sentence\n",
    "    for i in range(max_length):\n",
    "        # Get source mask\n",
    "        tgt_mask = model.get_tgt_mask(y_input.size(1)).to(device)\n",
    "        \n",
    "        pred = model(input_sequence, y_input, tgt_mask)\n",
    "        next_item = pred.topk(1)[1].view(-1)[0].item() # num with highest probability, twas view(-1)[-1] before\n",
    "        \n",
    "        ## Some wacky stuff to look at the inner workings :)\n",
    "        # print('The pred')\n",
    "        # print(pred)\n",
    "        # print('The pred.topk(2)')\n",
    "        # print(pred.topk(2))\n",
    "        # print('The pred.topk(2)[1]')\n",
    "        # print(pred.topk(2)[1])\n",
    "        # print('The pred.topk(2)[1].view(-1)')\n",
    "        # print(pred.topk(2)[1].view(-1))\n",
    "        # print('The pred.topk(2)[1].view(-1)[-1]')\n",
    "        # print(pred.topk(2)[1].view(-1)[-1])\n",
    "        \n",
    "        next_item = torch.tensor([[next_item]], device=device)\n",
    "\n",
    "        # Concatenate previous input with predicted best word\n",
    "        y_input = torch.cat((y_input, next_item), dim=1)\n",
    "\n",
    "        # Stop if model predicts end of sentence\n",
    "        if next_item.view(-1).item() == EOS_token:\n",
    "            break\n",
    "        elif (len(y_input.view(-1)) >= len(input_sequence[0])):\n",
    "            break\n",
    "\n",
    "    return y_input.view(-1).tolist()\n",
    "  \n",
    "  \n",
    "# Here we test some examples to observe how the model predicts\n",
    "examples = [\n",
    "    torch.tensor([[8, 0, 0, 0, 0, 0, 0, 0, 0, 9]], dtype=torch.long, device=device),\n",
    "    torch.tensor([[8, 1, 2, 1, 1, 1, 1, 2, 1, 9]], dtype=torch.long, device=device),\n",
    "    torch.tensor([[8, 1, 0, 1, 0, 1, 0, 1, 0, 9]], dtype=torch.long, device=device),\n",
    "    torch.tensor([[8, 0, 1, 0, 1, 0, 1, 3, 1, 9]], dtype=torch.long, device=device),\n",
    "    torch.tensor([[8, 0, 1, 2, 1, 0, 1, 0, 1, 0, 1, 0, 9]], dtype=torch.long, device=device),\n",
    "    torch.tensor([[8, 0, 0, 0, 1, 0, 0, 0, 1, 9]], dtype=torch.long, device=device)\n",
    "]\n",
    "\n",
    "for idx, example in enumerate(examples):\n",
    "    result = predict(model, example)\n",
    "    print(f\"Example {idx+1}\")\n",
    "    print(f\"Input: {example.view(-1).tolist()[1:-1]}\")\n",
    "    print(f\"Continuation: {result[1:-1]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6408bbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "example_use.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
