{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22d286f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "805c181f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2190],\n",
      "         [0.3532],\n",
      "         [0.0474],\n",
      "         [0.3066]],\n",
      "\n",
      "        [[0.2560],\n",
      "         [0.8752],\n",
      "         [0.1437],\n",
      "         [0.8498]]])\n",
      "tensor([[[ 1.5899e-02, -5.1423e-02, -3.0294e-01, -4.0232e-01],\n",
      "         [-1.1244e-01,  2.8466e-02, -4.0180e-01, -2.9895e-01],\n",
      "         [ 1.8001e-01, -1.5358e-01, -1.7652e-01, -5.3452e-01],\n",
      "         [-6.7916e-02,  7.5148e-04, -3.6751e-01, -3.3481e-01]],\n",
      "\n",
      "        [[-1.9509e-02, -2.9382e-02, -3.3022e-01, -3.7380e-01],\n",
      "         [-6.1161e-01,  3.3920e-01, -7.8634e-01,  1.0315e-01],\n",
      "         [ 8.7929e-02, -9.6261e-02, -2.4745e-01, -4.6034e-01],\n",
      "         [-5.8730e-01,  3.2407e-01, -7.6761e-01,  8.3563e-02]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[[0.9862, 0.6988],\n",
      "         [0.9182, 0.1094],\n",
      "         [0.4937, 0.5580]],\n",
      "\n",
      "        [[0.5667, 0.1993],\n",
      "         [0.7072, 0.6829],\n",
      "         [0.6924, 0.2154]],\n",
      "\n",
      "        [[0.2458, 0.5928],\n",
      "         [0.8755, 0.0358],\n",
      "         [0.9921, 0.5045]],\n",
      "\n",
      "        [[0.1643, 0.4938],\n",
      "         [0.0528, 0.7670],\n",
      "         [0.5191, 0.1879]],\n",
      "\n",
      "        [[0.7152, 0.9988],\n",
      "         [0.9915, 0.6097],\n",
      "         [0.7983, 0.5485]]])\n",
      "tensor([[[-0.2933],\n",
      "         [ 0.0548],\n",
      "         [-0.4702]],\n",
      "\n",
      "        [[-0.1959],\n",
      "         [-0.4353],\n",
      "         [-0.1378]],\n",
      "\n",
      "        [[-0.6283],\n",
      "         [ 0.0796],\n",
      "         [-0.1631]],\n",
      "\n",
      "        [[-0.6080],\n",
      "         [-0.8475],\n",
      "         [-0.2144]],\n",
      "\n",
      "        [[-0.6374],\n",
      "         [-0.2323],\n",
      "         [-0.2977]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Linear check [X]\n",
    "N = 2\n",
    "length = 4\n",
    "seq = torch.rand((2, 4))\n",
    "seq = torch.unsqueeze(seq, dim=2)\n",
    "\n",
    "d_model = 2\n",
    "embedding = nn.Linear(1, 4)\n",
    "\n",
    "print(seq)\n",
    "print(embedding(seq))\n",
    "\n",
    "\n",
    "# Out check\n",
    "N = 5\n",
    "target_len = 3\n",
    "d_model = 2\n",
    "\n",
    "decoder_out = torch.rand((N, target_len, d_model))\n",
    "print(decoder_out)\n",
    "\n",
    "out = nn.Linear(d_model, 1)\n",
    "\n",
    "model_out = out(decoder_out)\n",
    "\n",
    "print(model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bd06dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "N = 2000\n",
    "seq_len = 4\n",
    "SOS_token = -1e2\n",
    "EOS_token = 1e2\n",
    "\n",
    "# Generate data\n",
    "data = torch.rand((N, seq_len))\n",
    "\n",
    "# Generate target\n",
    "target = torch.zeros((N, seq_len-1))\n",
    "for i in range(seq_len-1):\n",
    "    target[:, i] = data[:, i] + data[:, i+1]\n",
    "    \n",
    "# Append SOS and EOS token\n",
    "SOS_ = SOS_token*torch.ones((N, 1))\n",
    "EOS_ = EOS_token*torch.ones((N, 1))\n",
    "\n",
    "data = torch.cat((SOS_, data), axis=1)\n",
    "data = torch.cat((data, EOS_), axis=1)\n",
    "\n",
    "target = torch.cat((SOS_, target), axis=1)\n",
    "target = torch.cat((target, EOS_), axis=1)\n",
    "\n",
    "# Unsqueeze so each entry becomes its own dimension, needed for the nn.Linear embedding\n",
    "data = torch.unsqueeze(data, dim=2)\n",
    "target = torch.unsqueeze(target, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77a788d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def batchify(data, target):\n",
    "    numMiniBatch = int(math.floor(data.shape[0]/100.0))\n",
    "    inputMiniBatches = data.chunk(numMiniBatch)\n",
    "    outputMiniBatches = target.chunk(numMiniBatch)\n",
    "    \n",
    "    return numMiniBatch, inputMiniBatches, outputMiniBatches\n",
    "\n",
    "num_batch, data_batches, target_batches = batchify(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c09a148",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout_p, max_len):\n",
    "        super().__init__()\n",
    "\n",
    "        # Info\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        # Encoding - From formula\n",
    "        pos_encoding = torch.zeros(max_len, d_model)\n",
    "        positions_list = torch.arange(0, max_len, dtype=torch.long).view(-1, 1) # 0, 1, 2, 3, 4, 5\n",
    "        division_term = torch.exp(torch.arange(0, d_model, 2).long() * (-math.log(10000.0)) / d_model) # 1000^(2i/dim_model)\n",
    "        \n",
    "        # PE(pos, 2i) = sin(pos/1000^(2i/d_model))\n",
    "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
    "        \n",
    "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/d_model))\n",
    "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
    "        \n",
    "        # Saving buffer (same as parameter without gradients needed)\n",
    "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
    "        \n",
    "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
    "        # Residual connection + pos encoding\n",
    "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])\n",
    "\n",
    "    \n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, d_model, n_head, n_layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.positional_encoder = PositionalEncoding(\n",
    "            d_model = d_model, \n",
    "            dropout_p = 0.1,\n",
    "            max_len = 100)\n",
    "        self.embedding = nn.Linear(1, d_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_head,\n",
    "            num_encoder_layers=n_layers,\n",
    "            num_decoder_layers=n_layers)\n",
    "        \n",
    "        # For floating point with one output, then self.out = nn.Linear(d_model, 1)\n",
    "        self.out = nn.Linear(d_model, 1) # Learned linear at the end where output of decoder is run through\n",
    "        \n",
    "    def get_tgt_mask(self, size):\n",
    "    \n",
    "        mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
    "        mask = mask.float()\n",
    "        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
    "        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
    "        \n",
    "        return mask\n",
    "        \n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None, src_key_padding_mask=None, tgt_key_padding_mask=None):\n",
    "        \n",
    "        src = (self.embedding(src) * math.sqrt(self.d_model)).to(device)\n",
    "        tgt = (self.embedding(tgt) * math.sqrt(self.d_model)).to(device)\n",
    "        src = self.positional_encoder(src)\n",
    "        tgt = self.positional_encoder(tgt)\n",
    "        \n",
    "        src = src.permute(1, 0, 2)\n",
    "        tgt = tgt.permute(1, 0, 2)\n",
    "        \n",
    "        transformer_output = self.transformer(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask, src_key_padding_mask=src_key_padding_mask, tgt_key_padding_mask=tgt_key_padding_mask).to(device)\n",
    "        output = self.out(transformer_output).to(device)\n",
    "        \n",
    "        output = output.permute(1, 2, 0).to(device)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "109a29f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "d_model = 16\n",
    "n_head = 2\n",
    "n_layers = 2\n",
    "\n",
    "model = TransformerModel(d_model, n_head, n_layers)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c7b3dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(model, data_batches, target_batches, num_batch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for i in range(num_batch):\n",
    "        data = data_batches[i].to(device)\n",
    "        target = target_batches[i].to(device)\n",
    "        \n",
    "        target_in = target[:, :-1]\n",
    "        target_expected = target[:, 1:]\n",
    "        \n",
    "        sequence_length = target_in.size(1)\n",
    "\n",
    "        tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
    "        src_mask = model.get_tgt_mask(data.size(1)).to(device)\n",
    "        \n",
    "        pred = model(data, target_in, src_mask, tgt_mask)\n",
    "        pred = torch.permute(pred, (0, 2, 1))\n",
    "        \n",
    "        loss = (criterion(pred, target_expected).type(torch.float))\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_loss += loss.detach().item()\n",
    "        \n",
    "    return total_loss\n",
    "    \n",
    "def train_loop(model, n_epochs, data, target, num_batch):\n",
    "    best_loss = 10000.0\n",
    "    best_model = copy.deepcopy(model).to(device)\n",
    "    loss_ = np.array([])\n",
    "    epochs = np.array([])\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        loss = train(model, data, target, num_batch)\n",
    "        loss_ = np.append(loss_, loss)\n",
    "        epochs = np.append(epochs, i)\n",
    "        \n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_model = copy.deepcopy(model).to(device)\n",
    "                     \n",
    "        if i % 10 == 0:\n",
    "            print(f'Epoch: {i}\\nTotal Loss: {loss}')\n",
    "            print(f'----------------------------------')\n",
    "    \n",
    "    return best_model, loss_, epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b521258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Total Loss: 49057.34521484375\n",
      "----------------------------------\n",
      "Epoch: 10\n",
      "Total Loss: 47502.649658203125\n",
      "----------------------------------\n",
      "Epoch: 20\n",
      "Total Loss: 47058.110595703125\n",
      "----------------------------------\n",
      "Epoch: 30\n",
      "Total Loss: 46585.136962890625\n",
      "----------------------------------\n",
      "Epoch: 40\n",
      "Total Loss: 46048.794189453125\n",
      "----------------------------------\n",
      "Epoch: 50\n",
      "Total Loss: 45511.4765625\n",
      "----------------------------------\n",
      "Epoch: 60\n",
      "Total Loss: 44871.1435546875\n",
      "----------------------------------\n",
      "Epoch: 70\n",
      "Total Loss: 44248.941650390625\n",
      "----------------------------------\n",
      "Epoch: 80\n",
      "Total Loss: 43585.76904296875\n",
      "----------------------------------\n",
      "Epoch: 90\n",
      "Total Loss: 42881.96337890625\n",
      "----------------------------------\n",
      "Epoch: 100\n",
      "Total Loss: 42167.56982421875\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 110\n",
    "best_model, loss_, epochs = train_loop(model, n_epochs, data_batches, target_batches, num_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704bba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_in = torch.tensor([[[np.pi], [1.0], [2.0], [3.0]]])\n",
    "example_out = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
