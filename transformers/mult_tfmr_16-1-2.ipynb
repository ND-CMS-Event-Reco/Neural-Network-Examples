{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "983ea017",
      "metadata": {
        "id": "983ea017"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np    \n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Utils for creating data + training \n",
        "'''\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import copy\n",
        "\n",
        "\n",
        "####################################\n",
        "#  Data generation + manipulation  #\n",
        "####################################\n",
        "def batchify(data, target):\n",
        "    num_batch = int(math.floor(data.shape[0] / 100.0))\n",
        "    input_batches = data.chunk(num_batch)\n",
        "    output_batches = target.chunk(num_batch)\n",
        "    \n",
        "    return num_batch, input_batches, output_batches\n",
        "\n",
        "def generateSeqs(N, in_len, data_range = (-1, 1), operation = 'subtraction', \n",
        "    method = 'neighbors', SOS_token = np.pi, EOS_token = -np.pi):\n",
        "    ''' \n",
        "        Args:\n",
        "            N (int)\n",
        "            in_len (int)\n",
        "            data_range (tuple) \n",
        "            operation (str)\n",
        "            method (str)\n",
        "            \n",
        "        Out\n",
        "            data\n",
        "            target\n",
        "    '''\n",
        "    \n",
        "    # Pull random floats in range (data_range[0], data_range[1])\n",
        "    data = (data_range[0] - data_range[1]) * torch.rand((N, in_len)) + data_range[1]\n",
        "    \n",
        "    target = torch.zeros((N, in_len - 1))\n",
        "    \n",
        "    if operation == 'subtraction':\n",
        "        op_func = subtractTensors\n",
        "    elif operation == 'multiplication':\n",
        "        op_func = multiplyTensors\n",
        "    elif operation == 'division':\n",
        "        op_func = divideTensors\n",
        "    elif operation == 'power':\n",
        "        op_func = exponentiateTensors\n",
        "    \n",
        "    for i in np.arange(0, in_len - 1, 1):\n",
        "        target[:, i] = op_func(data[:, i], data[:, i + 1])\n",
        "        \n",
        "    # Appent SOS and EOS token\n",
        "    SOS_ = SOS_token*torch.ones((N, 1))\n",
        "    EOS_ = EOS_token*torch.ones((N, 1))\n",
        "\n",
        "    data = torch.cat((SOS_, data), axis=1)\n",
        "    data = torch.cat((data, EOS_), axis=1)\n",
        "\n",
        "    target = torch.cat((SOS_, target), axis=1)\n",
        "    target = torch.cat((target, EOS_), axis=1)\n",
        "\n",
        "    # Unsqueeze so each entry becomes its own dimension, needed for the nn.Linear embedding\n",
        "    data = torch.unsqueeze(data, dim=2)\n",
        "    target = torch.unsqueeze(target, dim=2)\n",
        "    \n",
        "    return data, target\n",
        "     \n",
        "def subtractTensors(ten1, ten2):\n",
        "    return ten1 - ten2\n",
        "    \n",
        "def multiplyTensors(ten1, ten2):\n",
        "    return torch.mul(ten1, ten2)\n",
        "    \n",
        "def divideTensors(ten1, ten2):\n",
        "    return torch.mul(ten1, 1/ten2)\n",
        "\n",
        "def exponentiateTensors(ten1, ten2):\n",
        "    return torch.pow(ten1, ten2)\n",
        "    \n",
        "   \n",
        "\n",
        "\n",
        "###############################\n",
        "#       Training              #\n",
        "###############################   \n",
        "\n",
        "def train_epoch(model, opt, criterion, scheduler, device, data_batches, target_batches, num_batch, verbose = False):\n",
        "    ''' Train transformer model\n",
        "    \n",
        "        Args:\n",
        "            model (FloatTransformer)\n",
        "            opt\n",
        "            criterion\n",
        "            device (str)\n",
        "            data_batches (tuple of tensors)\n",
        "            target_batches (tuple of tensors)\n",
        "            num_batch (int)\n",
        "    '''\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for i in range(num_batch):\n",
        "        data = data_batches[i].to(device)\n",
        "        target = target_batches[i].to(device)\n",
        "        \n",
        "        # Take SOS to last token before EOS as target input\n",
        "        target_in = target[:, :-1].to(device)\n",
        "        \n",
        "        # Take first input to EOS as target expected from transformer\n",
        "        target_expected = target[:, 1:].to(device)\n",
        "        \n",
        "        # Create masks\n",
        "        tgt_mask = model.get_tgt_mask(target_in.size(1)).to(device)\n",
        "        src_mask = model.get_tgt_mask(data.size(1)).to(device)\n",
        "        \n",
        "        pred = model(data, target_in, src_mask, tgt_mask)\n",
        "        \n",
        "        if i == 0 and verbose:\n",
        "            print('data', data)\n",
        "            print('tgt in', target_in)\n",
        "            print('pred', pred)\n",
        "            print('expected', target_expected)\n",
        "        \n",
        "        loss = (criterion(pred, target_expected).type(torch.float))\n",
        "        \n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        total_loss += loss.detach().item()\n",
        "        \n",
        "    scheduler.step()\n",
        "    return total_loss\n",
        "    \n",
        "def train(model, n_epochs, opt, criterion, scheduler, device, data_batches, target_batches, num_batch):\n",
        "    best_loss = 10000.0\n",
        "    best_model = copy.deepcopy(model).to(device)\n",
        "    loss_ = np.array([])\n",
        "    epochs = np.array([])\n",
        "    \n",
        "    for i in range(n_epochs):\n",
        "        loss = train_epoch(model, opt, criterion, scheduler, device, data_batches, target_batches, num_batch)\n",
        "        loss_ = np.append(loss_, loss)\n",
        "        epochs = np.append(epochs, i)\n",
        "        \n",
        "        if loss < best_loss:\n",
        "            best_loss = loss\n",
        "            best_model = copy.deepcopy(model).to(device)\n",
        "            \n",
        "        if i % 10 == 0:\n",
        "            print(f'Epoch: {i}\\nTotal Loss: {loss}')\n",
        "            print(f'-----------------------------------')\n",
        "            \n",
        "    return best_model, loss_, epochs\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    src, tgt = generateSeqs(10, 3, operation = 'multiplication')\n",
        "    print(src[0])\n",
        "    print(tgt[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdwfl82K7wqg",
        "outputId": "a4071341-700a-4f4c-9f88-c39d7326537e"
      },
      "id": "Jdwfl82K7wqg",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 3.1416],\n",
            "        [-0.1277],\n",
            "        [-0.5596],\n",
            "        [ 0.0442],\n",
            "        [-3.1416]])\n",
            "tensor([[ 3.1416],\n",
            "        [ 0.0715],\n",
            "        [-0.0247],\n",
            "        [-3.1416]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "  \n",
        "''' Module containing class definitions for a transformer implemented to \n",
        "    manipulate sequences of floats\n",
        "''' \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout_p, max_len):\n",
        "        super().__init__()\n",
        "\n",
        "        # Info\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        \n",
        "        # Encoding - From formula\n",
        "        pos_encoding = torch.zeros(max_len, d_model)\n",
        "        positions_list = torch.arange(0, max_len, dtype=torch.long).view(-1, 1) # 0, 1, 2, 3, 4, 5\n",
        "        division_term = torch.exp(torch.arange(0, d_model, 2).long() * (-math.log(10000.0)) / d_model) # 1000^(2i/dim_model)\n",
        "        \n",
        "        # PE(pos, 2i) = sin(pos/1000^(2i/d_model))\n",
        "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
        "        \n",
        "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/d_model))\n",
        "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
        "        \n",
        "        # Saving buffer (same as parameter without gradients needed)\n",
        "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
        "        \n",
        "    def forward(self, token_embedding: torch.tensor, train=False) -> torch.tensor:\n",
        "        # Residual connection + pos encoding\n",
        "        \n",
        "        # If training, apply dropout\n",
        "        if train:\n",
        "            return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])\n",
        "            \n",
        "        # If not, return without dropout\n",
        "        else:\n",
        "            return token_embedding + self.pos_encoding[:token_embedding.size(0), :]\n",
        "            \n",
        "class FloatTransformer(nn.Module):\n",
        "    def __init__(self, d_model, n_head, n_layers, device, in_element_dim = 1, out_element_dim = 1, pos_encoding = False):\n",
        "        ''' Initialize transformer model. Right now, dropout probability is set to 0 as that is what is found to work\n",
        "        with float manipulation\n",
        "        \n",
        "            Args:\n",
        "                d_model (int): dimension of embedding\n",
        "                n_head (int): number of attention heads\n",
        "                n_layers (int): number of encoders/decoders in encoder and decoder blocks\n",
        "                in_element_dim (int): The dimensionality of each element of a sequence inputted to the transformer. Default\n",
        "                set to 1\n",
        "                out_element_dim (int): The dimensionality of each element of a sequence outputted by the transformer. Default \n",
        "                set to 1\n",
        "        '''\n",
        "        super().__init__()\n",
        "        \n",
        "        ## Define dimensionality of each object of transformer\n",
        "        # N: Batch num\n",
        "        # S: Sequence length\n",
        "        # T: Target length\n",
        "        \n",
        "        # Initialize parameters + objects\n",
        "        self.d_model = d_model\n",
        "        self.device = device\n",
        "        \n",
        "        # Input dimensions: N x S x in_element_dim ---> Output dimensions: N x S x d_model\n",
        "        self.embedding = nn.Linear(in_element_dim, d_model)\n",
        "        \n",
        "        # If doing positional encoding, do so. If not, leave as identity\n",
        "        if pos_encoding:\n",
        "        \n",
        "            # Input dimensions: N x S x d_model ---> Output dimensions: N x S x d_model\n",
        "            self.positional_encoder = PositionalEncoding(\n",
        "                d_model = d_model, \n",
        "                dropout_p = 0.0,\n",
        "                max_len = 100)\n",
        "                \n",
        "        else:\n",
        "        \n",
        "            # Input dimensions: N x S x d_model ---> Output dimensions: N x S x d_model\n",
        "            self.positional_encoder = nn.Identity()\n",
        "\n",
        "        # Input dimensions: src: N x S x d_model & tgt: N x T x d_model ---> Output dimensions: N x T x d_model\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=n_head,\n",
        "            num_encoder_layers=n_layers,\n",
        "            num_decoder_layers=n_layers,\n",
        "            dropout = 0 )\n",
        "        \n",
        "        # Input dimensions: N x T x d_model ---> Output dimensions: N x T x out_element_dim\n",
        "        self.out = nn.Linear(d_model, out_element_dim) \n",
        "        \n",
        "    def get_tgt_mask(self, size) -> torch.Tensor:\n",
        "        ''' Generate square tensor of length size, where the lower triangular entries of the matrix\n",
        "        are set to 0 (true) and the rest are set to -inf (false)\n",
        "        \n",
        "            Args:\n",
        "                size (int): size of square tensor\n",
        "                \n",
        "            Out:\n",
        "                mask\n",
        "        '''\n",
        "        \n",
        "        # Create lower triangular matrix where triangular entries are 1 and the rest are 0\n",
        "        mask = torch.tril(torch.ones(size, size) == 1)\n",
        "        mask = mask.float()\n",
        "        \n",
        "        # Turn zeros to -inf\n",
        "        mask = mask.masked_fill(mask == 0, float('-inf'))\n",
        "       \n",
        "        # Turn ones in the matrix to zeros\n",
        "        mask = mask.masked_fill(mask == 1, float(0.0))\n",
        "        \n",
        "        return mask\n",
        "        \n",
        "    def forward(self, src, tgt, src_mask=None, tgt_mask=None, src_key_padding_mask=None, \n",
        "                tgt_key_padding_mask=None, verbose=False, train=False):\n",
        "        ''' Forward method of transformer. Let the following symbols be defined as below:\n",
        "            N - batch num\n",
        "            S - src sequence length\n",
        "            A - src element size\n",
        "            T - tgt sequence length\n",
        "            B - tgt element size\n",
        "            Important: src and tgt tensors must have three dimensions in order to use the forward\n",
        "            method properly.\n",
        "            \n",
        "            Args:\n",
        "                src (tensor): input sequence(s)   N x S x A\n",
        "                tgt (tensor): target sequence(s)  N x T x B\n",
        "                src_mask (tensor): mask for src input  S x S\n",
        "                tgt_mask (tensor): mask for tgt input  T x T\n",
        "                src_key_padding_mask (tensor): mask for any padding after EOS  N x S\n",
        "                tgt_key_padding_mask (tensor): mask for any padding after EOS  N x L\n",
        "                verbose (bool): boolean for printing out intermediate values\n",
        "                train (bool): boolean for whether or not to apply dropout w/ positional encoding\n",
        "        '''\n",
        "        \n",
        "        # Apply embeddings\n",
        "        src_emb = (self.embedding(src) * np.sqrt(self.d_model)).to(self.device)\n",
        "        tgt_emb = (self.embedding(tgt) * np.sqrt(self.d_model)).to(self.device)\n",
        "        \n",
        "        src_pemb = self.positional_encoder(src_emb)\n",
        "        tgt_pemb = self.positional_encoder(tgt_emb)\n",
        "        \n",
        "        # Do so that length is first?\n",
        "        src_pemb = src_pemb.permute(1, 0, 2)\n",
        "        tgt_pemb = tgt_pemb.permute(1, 0, 2)\n",
        "        \n",
        "        transformer_output = self.transformer(src_pemb, tgt_pemb, src_mask=src_mask, tgt_mask=tgt_mask, src_key_padding_mask=src_key_padding_mask, tgt_key_padding_mask=tgt_key_padding_mask).to(self.device)\n",
        "        \n",
        "        output = self.out(transformer_output).to(self.device)\n",
        "    \n",
        "        # Repermute so that batch size N is first again :>\n",
        "        output = output.permute(1, 0, 2).to(self.device)\n",
        "        \n",
        "        if verbose:\n",
        "            print(f'\\nTracing through the Transformer\\n')\n",
        "            print(f'Input: {src}')\n",
        "            print(f'Target: {tgt}')\n",
        "            \n",
        "            print(f'\\nAfter Embeddings')\n",
        "            print(f'Embedded input: {src_emb}')\n",
        "            print(f'Embedded target: {tgt_emb}')\n",
        "            \n",
        "            print(f'\\nAfter Positional Encoding')\n",
        "            print(f'Positionally encoded input: {src_pemb}')\n",
        "            print(f'Positionally encoded target: {tgt_pemb}')\n",
        "            \n",
        "            print(f'\\nAfter Encoder + Decoder Blocks')\n",
        "            print(f'Output from transformer: {transformer_output}')\n",
        "            \n",
        "            print(f'Final output: {output}')\n",
        "        \n",
        "        return output"
      ],
      "metadata": {
        "id": "P5ymyubL760X"
      },
      "id": "P5ymyubL760X",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "e3e468dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e3e468dd",
        "outputId": "fe128f0f-f871-4f66-a860-45950d759738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 3.1416],\n",
            "        [ 0.5828],\n",
            "        [ 0.7396],\n",
            "        [-0.0918],\n",
            "        [-3.1416]])\n",
            "tensor([[ 3.1416],\n",
            "        [ 0.4310],\n",
            "        [-0.0679],\n",
            "        [-3.1416]])\n",
            "Epoch: 0\n",
            "Total Loss: 161.44000736624002\n",
            "-----------------------------------\n",
            "Epoch: 10\n",
            "Total Loss: 0.3978856448084116\n",
            "-----------------------------------\n",
            "Epoch: 20\n",
            "Total Loss: 0.120656288236205\n",
            "-----------------------------------\n",
            "Epoch: 30\n",
            "Total Loss: 0.04845082746032858\n",
            "-----------------------------------\n",
            "Epoch: 40\n",
            "Total Loss: 0.02357302640848502\n",
            "-----------------------------------\n",
            "Epoch: 50\n",
            "Total Loss: 0.012955369385963422\n",
            "-----------------------------------\n",
            "Epoch: 60\n",
            "Total Loss: 0.008210779610635655\n",
            "-----------------------------------\n",
            "Epoch: 70\n",
            "Total Loss: 0.005929385823037592\n",
            "-----------------------------------\n",
            "Epoch: 80\n",
            "Total Loss: 0.004735058361802658\n",
            "-----------------------------------\n",
            "Epoch: 90\n",
            "Total Loss: 0.003958543666158221\n",
            "-----------------------------------\n",
            "Epoch: 100\n",
            "Total Loss: 0.0035652544052027224\n",
            "-----------------------------------\n",
            "Epoch: 110\n",
            "Total Loss: 0.003399432728656393\n",
            "-----------------------------------\n",
            "Epoch: 120\n",
            "Total Loss: 0.0032102871132337896\n",
            "-----------------------------------\n",
            "Epoch: 130\n",
            "Total Loss: 0.0031099020343390293\n",
            "-----------------------------------\n",
            "Epoch: 140\n",
            "Total Loss: 0.003053008732422313\n",
            "-----------------------------------\n",
            "Epoch: 150\n",
            "Total Loss: 0.003009410765116627\n",
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-dca8e27abe2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-9f81f6d2416c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, n_epochs, opt, criterion, scheduler, device, data_batches, target_batches, num_batch)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mloss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-9f81f6d2416c>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, opt, criterion, scheduler, device, data_batches, target_batches, num_batch, verbose)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tgt_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-9135e28f20d3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, src_key_padding_mask, tgt_key_padding_mask, verbose, train)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mtgt_pemb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt_pemb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mtransformer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_pemb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_pemb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    142\u001b[0m         output = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask,\n\u001b[1;32m    143\u001b[0m                               \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                               memory_key_padding_mask=memory_key_padding_mask)\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    249\u001b[0m                          \u001b[0mmemory_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                          \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                          memory_key_padding_mask=memory_key_padding_mask)\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mha_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_ff_block\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;31m# feed forward block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "d_model = 16\n",
        "n_head = 1\n",
        "n_layers = 2\n",
        "\n",
        "N = 30000\n",
        "seq_len = 3\n",
        "model = FloatTransformer(d_model, n_head, n_layers, device, pos_encoding = False).to(device)\n",
        "src, tgt = generateSeqs(N, seq_len, operation = \"multiplication\")\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.MSELoss()\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(opt, gamma=0.95)\n",
        "num_batch, src_batches, tgt_batches = batchify(src, tgt)\n",
        "    \n",
        "print(src_batches[0][0])\n",
        "print(tgt_batches[0][0])\n",
        "    \n",
        "n_epochs = 500\n",
        "best_model, loss, epochs = train(model, n_epochs, opt, criterion, scheduler, device, src_batches, tgt_batches, num_batch)\n",
        "\n",
        "plt.plot(epochs, loss)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "f0e9120a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0e9120a",
        "outputId": "6b85e4e8-4449-42c7-e91f-bbbaf2f2e430"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.2547],\n",
              "         [ 0.1039],\n",
              "         [-3.1427]]], grad_fn=<PermuteBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "trial_in = torch.tensor([[[np.pi], [0.5], [0.5], [0.2], [-np.pi]]]).to(device)\n",
        "trial_out = torch.tensor([[[np.pi], [0.25], [0.1]]]).to(device)\n",
        "src_mask = model.get_tgt_mask(5).to(device)\n",
        "tgt_mask = model.get_tgt_mask(3).to(device)\n",
        "model(trial_in, trial_out, src_mask, tgt_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "27bce567",
      "metadata": {
        "id": "27bce567"
      },
      "outputs": [],
      "source": [
        "## Convention\n",
        "# File name of model: OPERATION_NAME_tfmr_dmodel-nhead-layer\n",
        "torch.save(model.state_dict(), 'mult_tfmr_16-1-2')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "model_creator.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}