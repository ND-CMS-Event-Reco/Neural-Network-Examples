{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c9d73bb-e8d5-4aeb-a928-93db9ac6241c",
   "metadata": {
    "id": "2c9d73bb-e8d5-4aeb-a928-93db9ac6241c"
   },
   "source": [
    "# Transformer boilerplate code + how to use it\n",
    "##### by Daniel Melchor (dmh672@gmail.com)\n",
    "\n",
    "# https://towardsdatascience.com/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31985af0-d58e-4d01-8432-065537022502",
   "metadata": {
    "id": "31985af0-d58e-4d01-8432-065537022502"
   },
   "source": [
    "---\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "446258e5-7cf2-4a73-8dd7-7b7a43fdd98e",
   "metadata": {
    "id": "446258e5-7cf2-4a73-8dd7-7b7a43fdd98e",
    "outputId": "47b53fa2-a24f-4b6a-baca-90d30bdb34a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/rachel/anaconda3/envs/spanet/lib/python3.9/site-packages (1.8.1)\n",
      "Requirement already satisfied: numpy in /home/rachel/anaconda3/envs/spanet/lib/python3.9/site-packages (1.19.5)\n",
      "Requirement already satisfied: matplotlib in /home/rachel/anaconda3/envs/spanet/lib/python3.9/site-packages (3.5.1)\n",
      "Requirement already satisfied: typing-extensions in /home/rachel/anaconda3/envs/spanet/lib/python3.9/site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/rachel/anaconda3/envs/spanet/lib/python3.9/site-packages (from matplotlib) (3.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/rachel/anaconda3/envs/spanet/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/rachel/anaconda3/envs/spanet/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/rachel/anaconda3/envs/spanet/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/rachel/anaconda3/envs/spanet/lib/python3.9/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/rachel/anaconda3/envs/spanet/lib/python3.9/site-packages (from matplotlib) (9.0.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/rachel/anaconda3/envs/spanet/lib/python3.9/site-packages (from matplotlib) (4.29.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/rachel/anaconda3/envs/spanet/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3539f61f-fe7d-4428-b074-327a883f7f6e",
   "metadata": {
    "id": "3539f61f-fe7d-4428-b074-327a883f7f6e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c72c2ada-2106-4505-82f5-086e518080a5",
   "metadata": {
    "id": "c72c2ada-2106-4505-82f5-086e518080a5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim_model, dropout_p, max_len):\n",
    "        super().__init__()\n",
    "        # Modified version from: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "        # max_len determines how far the position can have an effect on a token (window)\n",
    "        \n",
    "        # Info\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        # Encoding - From formula\n",
    "        pos_encoding = torch.zeros(max_len, dim_model)\n",
    "        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1) # 0, 1, 2, 3, 4, 5\n",
    "        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model) # 1000^(2i/dim_model)\n",
    "        \n",
    "        # PE(pos, 2i) = sin(pos/1000^(2i/dim_model))\n",
    "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
    "        \n",
    "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
    "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
    "        \n",
    "        # Saving buffer (same as parameter without gradients needed)\n",
    "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
    "        \n",
    "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
    "        # Residual connection + pos encoding\n",
    "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "588b2729-866c-470a-aca7-6a3c5ea0b192",
   "metadata": {
    "id": "588b2729-866c-470a-aca7-6a3c5ea0b192",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Model from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/p/c80afbc9ffb1/\n",
    "    Edited by Juwan and Rachel\n",
    "    \"\"\"\n",
    "    # Constructor\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_tokens,\n",
    "        dim_model,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        dropout_p,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # INFO\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.dim_model = dim_model\n",
    "\n",
    "        # LAYERS\n",
    "        self.positional_encoder = PositionalEncoding(\n",
    "            dim_model=dim_model, dropout_p=dropout_p, max_len=5000\n",
    "        )\n",
    "        self.embedding = nn.Embedding(num_tokens, dim_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=dim_model,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dropout=dropout_p,\n",
    "        )\n",
    "        self.out = nn.Linear(dim_model, num_tokens)\n",
    "        \n",
    "    def forward(self, src, tgt, tgt_mask=None, src_pad_mask=None, tgt_pad_mask=None):\n",
    "        # Src size must be (batch_size, src sequence length)\n",
    "        # Tgt size must be (batch_size, tgt sequence length)\n",
    "\n",
    "        # Embedding + positional encoding - Out size = (batch_size, sequence length, dim_model)\n",
    "        src = self.embedding(src.int()) * math.sqrt(self.dim_model)\n",
    "        tgt = self.embedding(tgt.int()) * math.sqrt(self.dim_model)\n",
    "        src = self.positional_encoder(src)\n",
    "        tgt = self.positional_encoder(tgt)\n",
    "        \n",
    "        # We could use the parameter batch_first=True, but our KDL version doesn't support it yet, so we permute\n",
    "        # to obtain size (sequence length, batch_size, dim_model),\n",
    "        src = src.permute(1,0,2)\n",
    "        tgt = tgt.permute(1,0,2)\n",
    "\n",
    "        # Transformer blocks - Out size = (sequence length, batch_size, num_tokens)\n",
    "        transformer_out = self.transformer(src, tgt, tgt_mask=tgt_mask, src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask)\n",
    "        out = self.out(transformer_out)\n",
    "        \n",
    "        return out\n",
    "      \n",
    "    def get_tgt_mask(self, size) -> torch.tensor:\n",
    "        # Generates a squeare matrix where the each row allows one word more to be seen\n",
    "        mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
    "        mask = mask.float()\n",
    "        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
    "        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
    "        \n",
    "        # EX for size=5:\n",
    "        # [[0., -inf, -inf, -inf, -inf],\n",
    "        #  [0.,   0., -inf, -inf, -inf],\n",
    "        #  [0.,   0.,   0., -inf, -inf],\n",
    "        #  [0.,   0.,   0.,   0., -inf],\n",
    "        #  [0.,   0.,   0.,   0.,   0.]]\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def create_pad_mask(self, matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
    "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
    "        # [False, False, False, True, True, True]\n",
    "        return (matrix == pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ac39c4a-ab17-4487-a1ab-2b107e880574",
   "metadata": {
    "id": "8ac39c4a-ab17-4487-a1ab-2b107e880574",
    "outputId": "3ef96b46-f053-4d42-d2d2-c027c245f1d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562 batches of size 16\n",
      "187 batches of size 16\n"
     ]
    }
   ],
   "source": [
    "# If going from length 8 -> length 4, do SOS at [4] at put zeros for \n",
    "# the rest to keep length constant \n",
    "\n",
    "def generate_random_data(n):\n",
    "    SOS_token = np.array([8.0]) # For old, np.array([2])\n",
    "    EOS_token = np.array([9.0]) # For old, np.array([3])\n",
    "    length = 8 \n",
    "\n",
    "    data = []\n",
    "\n",
    "    for i in range(n):\n",
    "        X = np.random.randint(0, 3, length)\n",
    "        X = list(np.array(X, dtype = 'float'))\n",
    "        y = np.zeros(length)\n",
    "        for i in range(int(8/2)):\n",
    "            y[i] = float(X[2*i] + X[2*i+1])\n",
    "        X = np.concatenate((SOS_token, X, EOS_token))\n",
    "        y = np.concatenate((SOS_token, y, EOS_token))\n",
    "        data.append([X, y])\n",
    "        \n",
    "    return data\n",
    "\n",
    "def batchify_data(data, batch_size=16, padding=False, padding_token=-1):\n",
    "    batches = []\n",
    "    for idx in range(0, len(data), batch_size):\n",
    "        # We make sure we dont get the last bit if its not batch_size size\n",
    "        if idx + batch_size < len(data):\n",
    "            # Here you would need to get the max length of the batch,\n",
    "            # and normalize the length with the PAD token.\n",
    "            if padding:\n",
    "                max_batch_length = 0\n",
    "\n",
    "                # Get longest sentence in batch\n",
    "                for seq in data[idx : idx + batch_size]:\n",
    "                    if len(seq) > max_batch_length:\n",
    "                        max_batch_length = len(seq)\n",
    "\n",
    "                # Append X padding tokens until it reaches the max length\n",
    "                for seq_idx in range(batch_size):\n",
    "                    remaining_length = max_batch_length - len(data[idx + seq_idx])\n",
    "                    data[idx + seq_idx] += [padding_token] * float(remaining_length)\n",
    "                    \n",
    "            batches.append(np.array((data[idx : idx + batch_size])))\n",
    "\n",
    "    print(f\"{len(batches)} batches of size {batch_size}\")\n",
    "\n",
    "    return batches\n",
    "\n",
    "\n",
    "train_data = generate_random_data(9000)\n",
    "val_data = generate_random_data(3000)\n",
    "train_dataloader = batchify_data(train_data)\n",
    "val_dataloader = batchify_data(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6043e5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([8., 1., 1., 1., 0., 0., 0., 2., 2., 9.]), array([8., 2., 1., 0., 4., 0., 0., 0., 0., 9.])]\n"
     ]
    }
   ],
   "source": [
    "n = 20\n",
    "data = generate_random_data(n)\n",
    "print(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d04a60a-f013-4eda-b056-fc9bb1b1ea79",
   "metadata": {
    "id": "4d04a60a-f013-4eda-b056-fc9bb1b1ea79"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Transformer(\n",
    "    num_tokens=16, dim_model=8, num_heads=2, num_encoder_layers=3, num_decoder_layers=3, dropout_p=0.1\n",
    ").to(device)\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# CrossEntropyLoss -> may be typically used for categorization problems\n",
    "# Check more on that\n",
    "# Try MSE Loss next time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7bc6949f-2d59-44c3-8198-037e115106aa",
   "metadata": {
    "id": "7bc6949f-2d59-44c3-8198-037e115106aa"
   },
   "outputs": [],
   "source": [
    "# Remember to dig into pred, y_input, and y_expected within training\n",
    "# and validation\n",
    "\n",
    "def train_loop(model, opt, loss_fn, dataloader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        X, y = batch[:, 0], batch[:, 1]\n",
    "        X, y = torch.tensor(X).to(device), torch.tensor(y).to(device)\n",
    "\n",
    "        # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
    "        y_input = y[:,:-1]\n",
    "        y_expected = y[:,1:]\n",
    "        \n",
    "        # Get mask to mask out the next words\n",
    "        sequence_length = y_input.size(1)\n",
    "        tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
    "\n",
    "        # Standard training except we pass in y_input and tgt_mask\n",
    "        pred = model(X, y_input, tgt_mask)\n",
    "\n",
    "        # Permute pred to have batch size first again\n",
    "        pred = pred.permute(1, 2, 0)      \n",
    "        loss = loss_fn(pred, y_expected)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "        total_loss += loss.detach().item()\n",
    "        \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c23630c9-ce84-4996-8d8c-ff7919303331",
   "metadata": {
    "id": "c23630c9-ce84-4996-8d8c-ff7919303331"
   },
   "outputs": [],
   "source": [
    "def validation_loop(model, loss_fn, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X, y = batch[:, 0], batch[:, 1]\n",
    "            X, y = torch.tensor(X, dtype=torch.float, device=device), torch.tensor(y, dtype=torch.float, device=device)\n",
    "\n",
    "            # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
    "            y_input = y[:,:-1]\n",
    "            y_expected = y[:,1:]\n",
    "            \n",
    "            # Get mask to mask out the next words\n",
    "            sequence_length = y_input.size(1)\n",
    "            tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
    "\n",
    "            # Standard training except we pass in y_input and src_mask\n",
    "            pred = model(X, y_input, tgt_mask)\n",
    "\n",
    "            # Permute pred to have batch size first again\n",
    "            pred = pred.permute(1, 2, 0)      \n",
    "            loss = loss_fn(pred, y_expected)\n",
    "            total_loss += loss.detach().item()\n",
    "        \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e57ba93-cc8f-4b12-870f-6aed4dce94ab",
   "metadata": {
    "id": "5e57ba93-cc8f-4b12-870f-6aed4dce94ab",
    "outputId": "da2b56bb-f094-45fe-efe3-76666acb68f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validating model\n",
      "------------------------- Epoch 1 -------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found dtype Double but expected Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2306/2391614102.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loss_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2306/2391614102.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, opt, loss_fn, train_dataloader, val_dataloader, epochs)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Epoch {epoch + 1}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mtrain_loss_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2306/1492241653.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, opt, loss_fn, dataloader)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spanet/lib/python3.9/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spanet/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found dtype Double but expected Float"
     ]
    }
   ],
   "source": [
    "def fit(model, opt, loss_fn, train_dataloader, val_dataloader, epochs):\n",
    "    # Used for plotting later on\n",
    "    train_loss_list, validation_loss_list = [], []\n",
    "    \n",
    "    print(\"Training and validating model\")\n",
    "    for epoch in range(epochs):\n",
    "        print(\"-\"*25, f\"Epoch {epoch + 1}\",\"-\"*25)\n",
    "        \n",
    "        train_loss = train_loop(model, opt, loss_fn, train_dataloader)\n",
    "        train_loss_list += [train_loss]\n",
    "        \n",
    "        validation_loss = validation_loop(model, loss_fn, val_dataloader)\n",
    "        validation_loss_list += [validation_loss]\n",
    "        \n",
    "        print(f\"Training loss: {train_loss:.4f}\")\n",
    "        print(f\"Validation loss: {validation_loss:.4f}\")\n",
    "        print()\n",
    "        \n",
    "    return train_loss_list, validation_loss_list\n",
    "    \n",
    "train_loss_list, validation_loss_list = fit(model, opt, loss_fn, train_dataloader, val_dataloader, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f805ad-7748-4785-9066-c5500287a4af",
   "metadata": {
    "id": "40f805ad-7748-4785-9066-c5500287a4af",
    "outputId": "7d3e38be-0382-4311-9beb-15c60b3177d5"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_loss_list, label = \"Train loss\")\n",
    "plt.plot(validation_loss_list, label = \"Validation loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df24c30-15b0-471a-ac4d-a0975fbc6a7d",
   "metadata": {
    "id": "5df24c30-15b0-471a-ac4d-a0975fbc6a7d",
    "outputId": "7a7d4a5b-4f10-4cf4-cbe2-f204097bbf19"
   },
   "outputs": [],
   "source": [
    "def predict(model, input_sequence, max_length=15, SOS_token=8, EOS_token=9):\n",
    "    model.eval()\n",
    "    \n",
    "    y_input = torch.tensor([[SOS_token]], dtype=torch.float, device=device)\n",
    "    num_tokens = len(input_sequence[0])\n",
    "    \n",
    "    # Asks model to give only one item, the next thing it thinks is most probable \n",
    "    # to continue the sentence\n",
    "    for i in range(max_length):\n",
    "        # Get source mask\n",
    "        tgt_mask = model.get_tgt_mask(y_input.size(1)).to(device)\n",
    "        \n",
    "        pred = model(input_sequence, y_input, tgt_mask)\n",
    "        next_item = pred.topk(1)[1].view(-1)[0].item() # num with highest probability, twas view(-1)[-1] before\n",
    "        \n",
    "        ## Some wacky stuff to look at the inner workings :)\n",
    "        # print('The pred')\n",
    "        # print(pred)\n",
    "        # print('The pred.topk(2)')\n",
    "        # print(pred.topk(2))\n",
    "        # print('The pred.topk(2)[1]')\n",
    "        # print(pred.topk(2)[1])\n",
    "        # print('The pred.topk(2)[1].view(-1)')\n",
    "        # print(pred.topk(2)[1].view(-1))\n",
    "        # print('The pred.topk(2)[1].view(-1)[-1]')\n",
    "        # print(pred.topk(2)[1].view(-1)[-1])\n",
    "        \n",
    "        next_item = torch.tensor([[next_item]], device=device)\n",
    "\n",
    "        # Concatenate previous input with predicted best word\n",
    "        y_input = torch.cat((y_input, next_item), dim=1)\n",
    "\n",
    "        # Stop if model predicts end of sentence\n",
    "        if next_item.view(-1).item() == EOS_token:\n",
    "            break\n",
    "        elif (len(y_input.view(-1)) >= len(input_sequence[0])):\n",
    "            break\n",
    "\n",
    "    return y_input.view(-1).tolist()\n",
    "  \n",
    "  \n",
    "# Here we test some examples to observe how the model predicts\n",
    "examples = [\n",
    "    torch.tensor([[8, 0, 0, 0, 0, 0, 0, 0, 0, 9]], dtype=torch.float, device=device),\n",
    "    torch.tensor([[8, 1, 2, 1, 1, 1, 1, 2, 1, 9]], dtype=torch.float, device=device),\n",
    "    torch.tensor([[8, 1, 0, 1, 0, 1, 0, 1, 0, 9]], dtype=torch.float, device=device),\n",
    "    torch.tensor([[8, 0, 1, 0, 1, 0, 1, 3, 1, 9]], dtype=torch.float, device=device),\n",
    "    torch.tensor([[8, 0, 1, 2, 1, 0, 1, 0, 1, 0, 1, 0, 9]], dtype=torch.float, device=device),\n",
    "    torch.tensor([[8, 0, 0, 0, 1, 0, 0, 0, 1, 9]], dtype=torch.float, device=device)\n",
    "]\n",
    "\n",
    "for idx, example in enumerate(examples):\n",
    "    result = predict(model, example)\n",
    "    print(f\"Example {idx+1}\")\n",
    "    print(f\"Input: {example.view(-1).tolist()[1:-1]}\")\n",
    "    print(f\"Continuation: {result[1:-1]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6408bbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "example_use.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
